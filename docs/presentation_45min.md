# Обзор проекта автотестов LDS (45 минут) — план выступления и спикер-ноты

Целевая аудитория: ручные тестировщики (пользователи автотестов).  
Дополнительная аудитория: 1–2 инженера/разработчика (для ответов на вопросы).

Цели встречи:
- Понять **что именно проверяют** автотесты и почему это соответствует фронту (контракты).
- Научиться **запускать тесты на своём стенде из пайпа** и читать результат в TestOps.
- Понять, как расширять покрытие “в ширину”: добавлять новые **datasets**.

## Тайминг и сценарий (45 минут)

### 0–5 мин — Интро: что у нас есть и зачем
Тезисы:
- Автотесты повторяют ручной E2E флоу: подготовили стенд → запустили имитатор → проверяем UI‑контракты через `api-gateway`.
- Отличие от “ручного”: всё запускается из пайпа и **результат хранится** (TestOps).

Что показать:
- Репозиторий: `tests/test_smoke.py`, `test_config/datasets/`, `conftest.py`.
- TestOps: где лежит TMS/кейсы и где testruns.

### 5–10 мин — Достижения: автотесты + TestOps (TMS + прогоны)
Тезисы:
- В TestOps есть:
  - **Тест‑кейсы (TMS)**, как в Allure: описание, вложения (архив данных), ссылки.
  - **История прогонов** (testruns): фактический результат каждого запуска, шаги, ассёрты, вложения.
- Автотесты добавляют `test_case_id` и `offset` в pytest/allure на основании datasets-конфигов.

Что показать:
- В TestOps открыть любой кейс (например из select_6) и показать:
  - `test_case_id`
  - вложение с данными (архив)
  - описание/шаги
- Открыть любой testrun и показать группировку по наборам.

### 10–15 мин — Покрытие данными (datasets): что покрыто сейчас
Тезисы:
- “Отборы брались с заводских испытаний СОУ”.
- Сейчас покрыты 5 наборов:
  - **стационар**: `Select_6_tn3_56km_113`, `Select_7_tn3_130km_113`
  - **останов**: `Select_4_tn3_215km_113` (stationaryStatus=STOPPED)
  - **одна утечка с большим допуском времени**: `Select_17_tn3_75km_417`
  - **две утечки (multi‑leak)**: `Select_19_20_tn3_75_181km_649`
- Все наборы — “с утечками” и дают проверку функциональности вокруг событий утечки.

Что показать:
- `test_config/datasets/` и быстро открыть 2–3 файла (select_4, select_6, select_19_20), показать:
  - `suite_name`, `suite_data_id`, `archive_name`
  - где задана утечка: `leak=...` или `leaks=[...]`
  - чем отличаются offsets и временные окна

### 15–28 мин — Детальный разбор select_19_20 (2 утечки): что именно проверяем
Тезисы:
- Это “богатый” набор: две утечки, разные координаты и разные окна.
- В datasets видно параметры утечек:
  - координата (meters)
  - объём (m3)
  - интервал от старта имитатора до утечки (секунды)
  - допустимое время обнаружения
  - когда запускать проверку (offset, минуты)

Что показать:
- Открыть `test_config/datasets/select_19_20.py` и показать:
  - Leak #1: 75км, `leak_start_interval_seconds ~ 2460`, `offset ~ 47`
  - Leak #2: 181км, `leak_start_interval_seconds ~ 3300`, `offset ~ 61`
- Пояснить: offset — это **когда мы идём проверять**, а интервал/allowed — это **какое окно времени считаем корректным**.

### 28–38 мин — “Контракты” фронта: какие запросы шлём и какие поля проверяем
Тезисы:
- Автотесты не кликают UI. Они **имитируют запросы фронта** в `api-gateway` (WebSocket/SignalR).
- Есть два класса взаимодействий:
  - **Синхронные** (“как REST”): запрос → ответ. В коде это `invoke()` + ожидание по `invocation_id`.
  - **Асинхронные подписки**: подписались → приходят события/обновления по типу контента. В коде это `invoke()` + ожидание по `message_type`.
- “Объект данных” в нашей терминологии — это контент‑тип сообщения (например `AllLeaksInfoContent`), который фронт подписывает и получает обновления.

Что показать (конкретика):
- В `test_scenarios/scenarios.py` открыть функции:
  - `basic_info`: `getBasicInfoRequest` → проверяем `replyStatus`, список ТУ, `tuId/tuName`
  - `main_page_info`: `subscribeMainPageInfoRequest` → `stationaryStatus`
  - `leaks_content`: `SubscribeLeaksRequest` → поля утечки: `diagnosticAreaName`, `confirmationStatus`, `type`, `id`, `leakCoordinate`, `detectedAt`, `leakVolume`
  - `all_leaks_info` / `tu_leaks_info`: проверяем `ldsStatus`, `stationaryStatus`, `isMasked`, `isAcknowledged`, `pipeId`, `volume`, время/координату

Рекомендуемая “финальная” демонстрация:
- Открыть `leaks_content` и проговорить поля простыми словами:
  - “какую утечку нашли” (участок/идентификаторы)
  - “когда нашли” (detectedAt внутри окна)
  - “где нашли” (координата ± допуск)
  - “какого размера” (объём ± допуск)
  - “какой статус события” (confirmed/type)

### 38–42 мин — Как это запускается (в пайпе) и чем лучше ручного
Тезисы:
- В пайпе вы задаёте **стенд** через `STAND_NAME` — это ровно то же, что при ручном запуске.
- Два сценария запуска:
  - `SMOKE_PATH`: готовый хелпер для запуска smoke по выбранному suite (`pytest tests/test_smoke.py --suites=...`)
  - `TEST_PATH`: “произвольный” запуск (`pytest ...`) — нужен для точечных прогонов (1 тест/1 проверка)
- Выгода: стабильный запуск, автологика setup/teardown, единый отчёт и история.

### 42–45 мин — Как расширять покрытие “в ширину”: добавить dataset
Тезисы:
- Добавление набора — это **добавить файл** в `test_config/datasets/`.
- Тесты подхватятся автоматически, потому что configs автодискаверятся по суффиксу `_CONFIG`.
- Ручные тестировщики могут создавать новые наборы (при наличии данных в TestOps).

Что показать:
- `test_config/datasets/__init__.py` (автодискавер)
- краткий список того, что надо заполнить в новом dataset файле.

## Чек-лист перед выступлением (подготовка)
- Открыты вкладки:
  - TestOps: кейс + testrun
  - Repo: `test_config/datasets/select_19_20.py`, `test_scenarios/scenarios.py`, `clients/websocket_client.py`, `conftest.py`
- Есть готовые ответы на 3 типовых вопроса:
  - “Почему без UI?” → мы проверяем контракт, UI потребляет то же самое
  - “Почему offset такой?” → потому что утечка возникает в данных примерно тогда-то; offset задаёт момент проверки
  - “Почему два типа запросов?” → sync vs subscribe (пуш‑обновления)


